{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 in a row RL problem\n",
    "\n",
    "In this notebook I will try to address the 3 in a row game from a Reinforcement Learning perspective. I will try to take several basic approaches and see what works best.\n",
    "\n",
    "## How are the elements represented?\n",
    "\n",
    "The board is represented as a one-dimensional array. Positions are assigned as follows:\n",
    "\n",
    "| 0 | 1 | 2 |\n",
    "\n",
    "| 3 | 4 | 5 |\n",
    "\n",
    "| 6 | 7 | 8 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "config = {'rows': 3, 'cols': 3, 'pieces': 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task-specific functions that define the game "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(board, move):\n",
    "    return board[move] == 0\n",
    "\n",
    "def is_complete(section):\n",
    "    if np.all(section == 1) or np.all(section == 2):\n",
    "        return section[0]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def is_tie(board):\n",
    "    # Assumes it has been verified that nobody wins\n",
    "    return not np.count_nonzero(board == 0)\n",
    "        \n",
    "def who_wins(board):\n",
    "    sq_board = board.reshape(config['rows'], config['cols'])\n",
    "    # horizontal\n",
    "    for row in range(config['rows']):\n",
    "        for col in range(config['cols'] - config['pieces'] + 1):\n",
    "            if is_complete(sq_board[row, col:col+config['pieces']]):\n",
    "                return is_complete(sq_board[row, col:col+config['pieces']])\n",
    "    # vertical\n",
    "    for col in range(config['cols']):\n",
    "        for row in range(config['rows'] - config['pieces'] + 1):\n",
    "            if is_complete(sq_board[row:row+config['pieces'], col]):\n",
    "                return is_complete(sq_board[row:row+config['pieces'], col])\n",
    "    # positive diagonal\n",
    "    # TODO: further develop for a non-standard case (non-3x3 board)\n",
    "    if is_complete(sq_board[range(config['pieces']), range(config['pieces'] - 1, -1, -1)]):\n",
    "        return is_complete(sq_board[range(config['pieces']), range(config['pieces'] - 1, -1, -1)])\n",
    "    # negative diagonal\n",
    "    # TODO: further develop for a non-standard case (non-3x3 board)\n",
    "    if is_complete(sq_board[range(config['pieces']), range(config['pieces'])]):\n",
    "        return is_complete(sq_board[range(config['pieces']), range(config['pieces'])])\n",
    "    return 0\n",
    "\n",
    "def has_ended(board):\n",
    "    return who_wins(board) or is_tie(board)\n",
    "\n",
    "def play(agent1, agent2, verbose = True):\n",
    "    board = np.zeros(9, dtype = np.int64)\n",
    "    actions = []\n",
    "    while not who_wins(board):\n",
    "        # Agent 1 plays\n",
    "        action1 = agent1(board, 1)\n",
    "        actions.append(action1)\n",
    "        if not is_valid(board, action1):\n",
    "            print('Agent 1: Invalid move')\n",
    "            return 2, board, actions\n",
    "        board[action1] = 1\n",
    "        if who_wins(board):\n",
    "            if verbose:\n",
    "                print('Agent 1 wins')\n",
    "            return 1, board, actions\n",
    "        \n",
    "        if is_tie(board):\n",
    "            if verbose:\n",
    "                print('Tie')\n",
    "            return -1, board, actions\n",
    "        \n",
    "        # Agent 2 plays\n",
    "        action2 = agent2(board, 2)\n",
    "        actions.append(action2)\n",
    "        if not is_valid(board, action2):\n",
    "            print('Agent 2: Invalid move')\n",
    "            return 1, board, actions\n",
    "        board[action2] = 2\n",
    "        \n",
    "    if verbose:\n",
    "        print('Agent 2 wins')\n",
    "    return 2, board, actions\n",
    "\n",
    "def draw_board(board):\n",
    "    sq_board = board.reshape(config['rows'], config['cols']).tolist()    \n",
    "    for line in sq_board:\n",
    "        line = [' ' if piece == 0 else piece for piece in line]\n",
    "        line = ['X' if piece == 1 else piece for piece in line]\n",
    "        line = ['O' if piece == 2 else piece for piece in line]\n",
    "        print('|' + '|'.join(line) + '|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random agent\n",
    "This agent takes random (valid) moves at each step. It will be used as the _baseline_, to compete against other agents and check their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_agent(board, agent_code):\n",
    "    valid_moves = [move for move in range(config['rows'] * config['cols']) if is_valid(board, move)]\n",
    "    return random.choice(valid_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 1 wins\n",
      "|X| |O|\n",
      "|O|O| |\n",
      "|X|X|X|\n",
      "[6, 3, 0, 4, 7, 2, 8]\n"
     ]
    }
   ],
   "source": [
    "result, board, actions = play(random_agent, random_agent)\n",
    "\n",
    "draw_board(board)\n",
    "\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(ngames, agent1, agent2 = random_agent):\n",
    "    vict1 = 0\n",
    "    vict2 = 0\n",
    "    ties = 0\n",
    "    results = []\n",
    "\n",
    "    # Agent 1 plays first (roughly) half of the time\n",
    "    for game in range(ngames//2):\n",
    "        result, board, actions = play(agent1, agent2, verbose = False)\n",
    "        results.append(result)\n",
    "        vict1 += result == 1\n",
    "        vict2 += result == 2\n",
    "        ties += result == -1\n",
    "    \n",
    "    # Switching starting agent\n",
    "    for game in range(ngames//2, ngames):\n",
    "        result, board, actions = play(agent2, agent1, verbose = False)\n",
    "        results.append(result)\n",
    "        vict1 += result == 2\n",
    "        vict2 += result == 1\n",
    "        ties += result == -1\n",
    "        \n",
    "    print(vict1, vict2, ties)\n",
    "    print('Agent 1 wins ' + str(100*vict1/ngames) + '% of the time')\n",
    "    return vict1, vict2, ties, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413 457 130\n",
      "Agent 1 wins 41.3% of the time\n"
     ]
    }
   ],
   "source": [
    "v1, v2, _, results = get_performance(1000, random_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a 1-step lookahead agent\n",
    "With the aim of improving performance, I will design an agent that looks one step ahead to see which move will yield the best result. In this first implementation, the only fact that it will take into account is if he is going to win in the next step. This should be enough to significantly improve the random agent's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(board, agent_code, move=None):\n",
    "    if move is not None:\n",
    "        next_board = np.copy(board)\n",
    "        next_board[move] = agent_code\n",
    "        return get_reward(next_board, agent_code)\n",
    "    else:\n",
    "        rew = 0\n",
    "        h_ended = who_wins(board)\n",
    "        rew += 1e3*(h_ended == agent_code)\n",
    "        rew -= 1e3*(h_ended == (agent_code%2 + 1)) # Will be used in future implementations\n",
    "        return rew\n",
    "\n",
    "def agent_1step(board, agent_code):\n",
    "    valid_moves = [move for move in range(config['rows'] * config['cols']) if is_valid(board, move)]\n",
    "    mv_rew = [(move, get_reward(board, agent_code, move)) for move in valid_moves]\n",
    "    return random.choice([mv_r[0] for mv_r in mv_rew if (mv_r[1] >= max(mv_rew, key = lambda x: x[1])[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 1 wins\n",
      "|O| |O|\n",
      "|X|O| |\n",
      "|X|X|X|\n",
      "[3, 0, 8, 2, 6, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "result, board, actions = play(agent_1step, random_agent)\n",
    "\n",
    "draw_board(board)\n",
    "\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673 253 74\n",
      "Agent 1 wins 67.3% of the time\n"
     ]
    }
   ],
   "source": [
    "v1, v2, _, results = get_performance(1000, agent_1step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-step lookahead agent\n",
    "We will implement a minimax algorithm in order to build an agent that calculates the outcomes N steps ahead. Due to the relatively short duration of these games, with a small N we should achieve good enough results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(board, depth, maximizing_agent, agent_code):\n",
    "    if depth == 0 or has_ended(board):\n",
    "        return get_reward(board, agent_code)\n",
    "    if maximizing_agent:\n",
    "        val = -np.Inf\n",
    "        valid_moves = [move for move in range(config['rows'] * config['cols']) if is_valid(board, move)]\n",
    "        for move in valid_moves:\n",
    "            new_board = np.copy(board)\n",
    "            new_board[move] = agent_code\n",
    "            val = max(val, minimax(new_board, depth-1, False, agent_code))\n",
    "        return val\n",
    "    else: # minimizing agent\n",
    "        val = np.Inf\n",
    "        valid_moves = [move for move in range(config['rows'] * config['cols']) if is_valid(board, move)]\n",
    "        for move in valid_moves:\n",
    "            new_board = np.copy(board)\n",
    "            new_board[move] = agent_code%2 + 1\n",
    "            val = min(val, minimax(new_board, depth-1, True, agent_code))\n",
    "        return val\n",
    "    \n",
    "def get_reward_Nstep(board, agent_code, move, depth):\n",
    "    next_board = np.copy(board)\n",
    "    next_board[move] = agent_code\n",
    "    return minimax(next_board, depth-1, False, agent_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_3step(board, agent_code):\n",
    "    depth = 3\n",
    "    valid_moves = [move for move in range(config['rows'] * config['cols']) if is_valid(board, move)]\n",
    "    mv_rew = [(move, get_reward_Nstep(board, agent_code, move, depth)) for move in valid_moves]\n",
    "    return random.choice([mv_r[0] for mv_r in mv_rew if (mv_r[1] >= max(mv_rew, key = lambda x: x[1])[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 1 wins\n",
      "| |X|O|\n",
      "| |X| |\n",
      "| |X|O|\n",
      "[1, 8, 4, 2, 7]\n"
     ]
    }
   ],
   "source": [
    "result, board, actions = play(agent_3step, random_agent)\n",
    "\n",
    "draw_board(board)\n",
    "\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 15 4\n",
      "Agent 1 wins 81.0% of the time\n"
     ]
    }
   ],
   "source": [
    "v1, v2, _, results = get_performance(100, agent_3step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 17 2\n",
      "Agent 1 wins 81.0% of the time\n"
     ]
    }
   ],
   "source": [
    "def agent_5step(board, agent_code):\n",
    "    depth = 5\n",
    "    valid_moves = [move for move in range(config['rows'] * config['cols']) if is_valid(board, move)]\n",
    "    mv_rew = [(move, get_reward_Nstep(board, agent_code, move, depth)) for move in valid_moves]\n",
    "    return random.choice([mv_r[0] for mv_r in mv_rew if (mv_r[1] >= max(mv_rew, key = lambda x: x[1])[1])])\n",
    "\n",
    "v1, v2, _, results = get_performance(100, agent_5step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
